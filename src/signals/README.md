## Signals

Signals are generated by scanning datasets. All of the code for scanning those
datasets is stored in `src/indicators`. This repository contains the overall
workflow for converting indicator alerts into a signals dataset and emails.

### Generating signals

For each indicator `update_{...}.R` script, `generate_signals()` is the
primary workhorse. The process that flows through the function roughly follows:

1. Create an alerts dataset from the wrangled data
2. If any new alerts, generate all the email content, from maps and plots to text
3. Create Mailchimp templates and campaigns
4. Store out all of this information, including URLs and Mailchimp IDs to campaign content and drafts
are staged to `output/{indicator_id}/signals.parquet`

### Approving signals

Once signals have been generated, they need to be approved. This is manually done by reviewing
the campaign URLs, but final approveal is done by triaging the outputs.

If approved, then the data is removed from the staging
`output/{indicator_id}/signals.parquet` file and moved to the final Signals
dataset `ouput/signals.parquet` and pushed to HDX. The draft campaigns are
sent from Mailchimp.

If during triage the campaigns need to be fixed, then they can be deleted,
with all content on Mailchimp deleted. Since there are numerous files stored up on
Mailchimp, from files to templates to campaigns, it is always better to delete
programmatically with the functions available in this folder. It esnures all content is
removed from Mailchimp using their IDs before erasing the data from stage.

If nothing is specified, the campaigns are not sent and the data remains staged for 
further action.

### Other scripts

The other scripts in this section are helpers that feed into the process of generating and triaging signals.
None of the actual runs are coded in this area. See the `src/indicators` directory or the `.github` workflows
to see the process in action.
